<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>Bystander Coach VR</title>
  <meta name="description" content="VR training simulation for bystander intervention.">
  <script src="https://aframe.io/releases/1.5.0/aframe.min.js"></script>
  
  <style>
    /* Simple CSS for the 2D overlay UI (mic button) */
    body { margin: 0; }
    #mic-ui {
      position: fixed;
      bottom: 20px;
      left: 20px;
      z-index: 1000;
      background-color: rgba(0, 0, 0, 0.7);
      padding: 10px;
      border-radius: 8px;
      font-family: sans-serif;
      color: white;
    }
    #mic-ui button {
      padding: 8px 12px;
      border: none;
      background-color: #3f51b5;
      color: white;
      border-radius: 4px;
      cursor: pointer;
    }
    #mic-ui button:disabled {
      background-color: #555;
      cursor: not-allowed;
    }
    /* Hidden canvas for PNG export */
    #feedbackCanvas {
      display: none;
    }
  </style>
</head>

<body>
  <canvas id="feedbackCanvas"></canvas>
  
  <div id="mic-ui">
    <button id="enableMicButton">Enable Mic</button>
    <p id="micStatus" style="font-size: 12px; margin-top: 5px;">Mic access required for voice input.</p>
  </div>

  <a-scene webxr="optionalFeatures: true;">
    
    <a-assets></a-assets>

    <a-sky color="#ECEFF1"></a-sky>
    <a-light type="ambient" color="#888"></a-light>
    <a-light type="directional" position="-1 1 2" intensity="0.6"></a-light>
    <a-plane position="0 0 -4" rotation="-90 0 0" width="30" height="30" color="#78909C" shadow></a-plane>

    <a-entity id="player-rig" position="0 1.6 0">
      <a-camera id="camera">
        <a-cursor
          raycaster="objects: .clickable"
          fuse="false"
          position="0 0 -1"
          geometry="primitive: ring; radiusInner: 0.01; radiusOuter: 0.015"
          material="color: #FFF; shader: flat">
        </a-cursor>
      </a-camera>
      <a-entity id="right-hand" laser-controls="hand: right" raycaster="objects: .clickable; far: 5;"></a-entity>
      <a-entity id="left-hand" laser-controls="hand: left" raycaster="objects: .clickable; far: 5;"></a-entity>
    </a-entity>

    <a-sphere id="hover-dot" radius="0.01" color="#FFEB3B" shader="flat" visible="false"></a-sphere>

    <a-entity id="main-panel" position="0 1.2 -1.2">
      <a-plane width="1.2" height="1" color="#263238" side="double"></a-plane>

      <a-text id="subtitle-text" value="Loading scenario..."
              align="center" color="#FFFFFF" width="1.1" wrap-count="35"
              position="0 0.35 0.01"></a-text>

      <a-text id="transcript-text" value="Your response will appear here."
              align="left" color="#B0BEC5" width="1" wrap-count="50"
              position="-0.5 0.15 0.01" font-size="0.05"></a-text>

      <a-entity id="btn-direct" class="clickable button" position="0 -0.05 0.01">
        <a-plane width="0.8" height="0.15" color="#00796B"></a-plane>
        <a-text value="Direct Approach" align="center" color="#FFFFFF" width="2"></a-text>
      </a-entity>
      <a-entity id="btn-distract" class="clickable button" position="0 -0.25 0.01">
        <a-plane width="0.8" height="0.15" color="#512DA8"></a-plane>
        <a-text value="Distract" align="center" color="#FFFFFF" width="2"></a-text>
      </a-entity>
      <a-entity id="btn-delegate" class="clickable button" position="0 -0.45 0.01">
        <a-plane width="0.8" height="0.15" color="#F57C00"></a-plane>
        <a-text value="Delegate" align="center" color="#FFFFFF" width="2"></a-text>
      </a-entity>

      <a-entity id="btn-speak" class="clickable button" position="0.45 0.1 0.01">
        <a-circle radius="0.07" color="#C62828"></a-circle>
        <a-text value="Speak Now" align="center" color="#FFFFFF" width="0.5" position="0 -0.1 0"></a-text>
      </a-entity>
    </a-entity>

    <a-entity id="feedback-card" position="0 1.2 -1.1" visible="false">
      <a-plane width="1.1" height="1.2" color="#37474F" side="double"></a-plane>
      <a-text value="Feedback Report" align="center" color="#FFFFFF" width="2" position="0 0.5 0.01"></a-text>
      
      <a-text id="feedback-line-1" value="[Your Last Response]" align="left" color="#CFD8DC" width="1" position="-0.5 0.35 0.01"></a-text>
      <a-text id="feedback-line-2" value="[Detected Tone]" align="left" color="#CFD8DC" width="1" position="-0.5 0.25 0.01"></a-text>
      
      <a-text id="feedback-good" value="[What you did well]" align="left" color="#A5D6A7" width="1" wrap-count="45" position="-0.5 0.1 0.01"></a-text>
      <a-text id="feedback-suggestion" value="[Try this next time]" align="left" color="#FFCC80" width="1" wrap-count="45" position="-0.5 -0.1 0.01"></a-text>
      
      <a-entity id="btn-save-card" class="clickable button" position="-0.25 -0.45 0.01">
        <a-plane width="0.4" height="0.15" color="#1E88E5"></a-plane>
        <a-text value="Save Card" align="center" color="#FFFFFF" width="2"></a-text>
      </a-entity>
      <a-entity id="btn-replay" class="clickable button" position="0.25 -0.45 0.01">
        <a-plane width="0.4" height="0.15" color="#43A047"></a-plane>
        <a-text value="Replay" align="center" color="#FFFFFF" width="2"></a-text>
      </a-entity>
    </a-entity>
    
  </a-scene>

  <script>
    // Wait until the DOM and A-Frame scene are fully loaded
    window.addEventListener('DOMContentLoaded', () => {

      // --- 1. SCENARIO DATA ---
      // This JSON object contains the entire branching narrative for the training.
      const SCENARIO_BUS_V1 = {
        turn1: {
          npc_line: "Two people are arguing on a bus. One person says loudly, 'Why are you even in this country? Go back where you came from!'",
          good_keywords: ["stop", "not okay", "leave them alone", "that's enough", "help", "security"],
          bad_keywords: ["shut up", "idiot", "fight", "stupid"],
          branches: {
            STRONG: { npc_react: "The aggressor looks at you, surprised. 'What did you say?'", outcome: 'stall' },
            NEUTRAL: { npc_react: "They ignore you and continue yelling.", outcome: 'stall' },
            ESCALATE: { npc_react: "The aggressor turns on you. 'Mind your own business!'", outcome: 'escalate' }
          }
        },
        turn2: {
          npc_line: "The situation is tense. The target looks scared. What do you do now?",
          good_keywords: ["calm", "let's talk", "security", "driver", "help", "separate"],
          bad_keywords: ["fight", "punch", "moron"],
          branches: {
            STRONG: { npc_react: "The aggressor hesitates, seeing you're serious. They back down.", outcome: 'cooling' },
            NEUTRAL: { npc_react: "The argument continues, but doesn't get worse.", outcome: 'stall' },
            ESCALATE: { npc_react: "The situation gets more heated and dangerous.", outcome: 'escalate' }
          }
        }
      };
      
      // --- 2. STATE MANAGEMENT ---
      let currentTurn = 1;
      let gameActive = true;
      let finalOutcome = null; // Stores the results for the feedback card
      
      // Audio processing variables
      let audioContext, analyser, microphoneStream, dataArray;
      let isMicEnabled = false;

      // Web Speech API for speech-to-text
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      let recognition = null;
      if (SpeechRecognition) {
        recognition = new SpeechRecognition();
        recognition.continuous = false;
        recognition.lang = 'en-US';
        recognition.interimResults = false;
      }

      // --- 3. ELEMENT REFERENCES ---
      // Caching references to DOM/A-Frame elements for performance.
      const subtitleTextEl = document.querySelector('#subtitle-text');
      const transcriptTextEl = document.querySelector('#transcript-text');
      const mainPanelEl = document.querySelector('#main-panel');
      const feedbackCardEl = document.querySelector('#feedback-card');
      const hoverDotEl = document.querySelector('#hover-dot');
      
      // --- 4. CORE LOGIC ---

      /**
       * Initializes the scenario or resets it to the first turn.
       */
      function startScenario() {
        currentTurn = 1;
        gameActive = true;
        finalOutcome = null;
        mainPanelEl.setAttribute('visible', 'true');
        feedbackCardEl.setAttribute('visible', 'false');
        transcriptTextEl.setAttribute('value', 'Choose an option or use your voice.');
        startTurn(1);
      }

      /**
       * Updates the UI to reflect the current turn of the scenario.
       * @param {number} turnNumber - The turn to display (1 or 2).
       */
      function startTurn(turnNumber) {
        const turnData = SCENARIO_BUS_V1[`turn${turnNumber}`];
        if (turnData) {
          subtitleTextEl.setAttribute('value', turnData.npc_line);
        }
      }

      /**
       * Processes the player's choice (from a button or voice) and advances the scenario.
       * @param {string} playerText - The text from the player's choice or transcript.
       * @param {string} tone - The detected tone ('CALM', 'ASSERTIVE', 'AGGRESSIVE').
       */
      function processPlayerChoice(playerText, tone) {
        if (!gameActive) return;

        // Display player's action
        transcriptTextEl.setAttribute('value', `You said: "${playerText}"\nTone: ${tone}`);

        const turnData = SCENARIO_BUS_V1[`turn${currentTurn}`];
        let branchKey = 'NEUTRAL'; // Default branch

        // Scoring logic
        const textLower = playerText.toLowerCase();
        const hasGoodKeyword = turnData.good_keywords.some(kw => textLower.includes(kw));
        const hasBadKeyword = turnData.bad_keywords.some(kw => textLower.includes(kw));
        
        if (tone === 'AGGRESSIVE' || hasBadKeyword) {
          branchKey = 'ESCALATE';
        } else if (hasGoodKeyword && tone !== 'AGGRESSIVE') {
          branchKey = 'STRONG';
        }
        
        const result = turnData.branches[branchKey];
        playBeep(result.outcome === 'cooling' ? 'success' : 'neutral');
        
        // Store the result for the feedback card
        finalOutcome = {
            playerText,
            tone,
            outcome: result.outcome,
            turn: currentTurn
        };
        
        // Update subtitle with NPC reaction
        subtitleTextEl.setAttribute('value', `NPC Reacts: ${result.npc_react}`);

        // Advance or end the game
        setTimeout(() => {
          currentTurn++;
          if (currentTurn > 2 || result.outcome === 'cooling') {
            endScenario();
          } else {
            startTurn(currentTurn);
          }
        }, 4000); // 4-second delay to read the reaction
      }

      /**
       * Ends the scenario and displays the feedback card.
       */
      function endScenario() {
        gameActive = false;
        mainPanelEl.setAttribute('visible', 'false');
        feedbackCardEl.setAttribute('visible', 'true');
        populateFeedbackCard();
      }

      /**
       * Fills the feedback card with personalized advice based on the final outcome.
       */
      function populateFeedbackCard() {
          const card = {
            line1: `Your response: "${finalOutcome.playerText}"`,
            line2: `Detected tone: ${finalOutcome.tone}`,
            good: '',
            suggestion: ''
          };
          
          if (finalOutcome.outcome === 'cooling') {
              card.good = 'âœ”ï¸ Well done! You chose a strong, assertive response that de-escalated the situation effectively.';
              card.suggestion = 'ðŸ’¡ To improve further, remember to also check on the person who was targeted after the situation is calm.';
          } else {
              card.good = 'âœ”ï¸ Good job for trying to intervene. Taking action is the first and most important step.';
              card.suggestion = `ðŸ’¡ Your approach led to a stall. Next time, try being more direct with a clear command like "Stop that." or by delegating to an authority figure like the bus driver.`;
          }

          document.querySelector('#feedback-line-1').setAttribute('value', card.line1);
          document.querySelector('#feedback-line-2').setAttribute('value', card.line2);
          document.querySelector('#feedback-good').setAttribute('value', card.good);
          document.querySelector('#feedback-suggestion').setAttribute('value', card.suggestion);
      }


      // --- 5. AUDIO & VOICE PROCESSING ---

      /**
       * Sets up the microphone using getUserMedia and creates an AudioContext.
       */
      function setupMic() {
        const micButton = document.querySelector('#enableMicButton');
        const micStatus = document.querySelector('#micStatus');

        if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
          navigator.mediaDevices.getUserMedia({ audio: true })
            .then(stream => {
              isMicEnabled = true;
              microphoneStream = stream;
              audioContext = new (window.AudioContext || window.webkitAudioContext)();
              analyser = audioContext.createAnalyser();
              analyser.fftSize = 2048;
              const source = audioContext.createMediaStreamSource(microphoneStream);
              source.connect(analyser);
              dataArray = new Uint8Array(analyser.frequencyBinCount);
              
              micButton.textContent = 'Mic Enabled';
              micButton.disabled = true;
              micStatus.textContent = 'Mic is active. Use the "Speak Now" button in VR.';
              playBeep('success');
            })
            .catch(err => {
              console.error('Mic permission denied:', err);
              micStatus.textContent = 'Mic access was denied.';
              micButton.disabled = false;
            });
        } else {
          micStatus.textContent = 'Mic access not supported by this browser.';
        }
      }

      /**
       * Analyzes the microphone input for 1 second to determine tone.
       * @returns {Promise<string>} A promise that resolves with the tone bucket ('CALM', 'ASSERTIVE', 'AGGRESSIVE').
       */
      function analyzeTone() {
        return new Promise(resolve => {
          if (!isMicEnabled) {
            resolve('ASSERTIVE'); // Default if mic is off
            return;
          }

          let rmsSum = 0;
          let zeroCrossings = 0;
          let samples = 0;
          const duration = 1000; // 1 second analysis
          const startTime = performance.now();

          function sample() {
            if (performance.now() - startTime > duration) {
              const avgRms = rmsSum / samples;
              
              // Pace proxy: High zero crossings can indicate agitated speech
              const paceProxy = zeroCrossings / samples;

              console.log(`Analysis complete: Avg RMS=${avgRms.toFixed(3)}, Pace Proxy=${paceProxy.toFixed(3)}`);
              
              // Determine tone bucket
              if (avgRms > 0.06 || paceProxy > 0.1) { // Note: RMS values are very sensitive. Scaled down.
                resolve('AGGRESSIVE');
              } else if (avgRms >= 0.025) {
                resolve('ASSERTIVE');
              } else {
                resolve('CALM');
              }
              return;
            }

            analyser.getByteTimeDomainData(dataArray);
            let sumSquares = 0;
            for (let i = 0; i < dataArray.length; i++) {
              const val = (dataArray[i] / 128.0) - 1.0; // Normalize to -1 to 1
              sumSquares += val * val;
            }
            rmsSum += Math.sqrt(sumSquares / dataArray.length);

            // Zero-crossing for pace proxy
            for (let i = 1; i < dataArray.length; i++) {
                if ((dataArray[i-1] - 128) * (dataArray[i] - 128) < 0) {
                    zeroCrossings++;
                }
            }

            samples++;
            requestAnimationFrame(sample);
          }
          sample();
        });
      }

      /**
       * Starts the speech recognition process.
       */
      function startSpeechRecognition() {
        return new Promise((resolve, reject) => {
          if (!recognition) {
            reject('Speech recognition not available.');
            return;
          }
          
          transcriptTextEl.setAttribute('value', 'Listening...');
          
          recognition.onresult = (event) => {
            const transcript = event.results[0][0].transcript;
            resolve(transcript);
          };

          recognition.onerror = (event) => {
            reject(`Speech recognition error: ${event.error}`);
          };
          
          recognition.onend = () => {
             // Recognition has ended
          };

          recognition.start();
        });
      }

      /**
       * Generates a simple tone using the Web Audio API.
       * @param {'success'|'error'|'neutral'} type - The type of beep to play.
       */
      function playBeep(type = 'neutral') {
        if (!audioContext) return;
        const oscillator = audioContext.createOscillator();
        const gainNode = audioContext.createGain();
        oscillator.connect(gainNode);
        gainNode.connect(audioContext.destination);

        gainNode.gain.setValueAtTime(0.2, audioContext.currentTime);
        
        switch(type) {
            case 'success':
                oscillator.frequency.setValueAtTime(800, audioContext.currentTime);
                break;
            case 'error':
                oscillator.frequency.setValueAtTime(300, audioContext.currentTime);
                break;
            default:
                oscillator.frequency.setValueAtTime(520, audioContext.currentTime);
        }

        oscillator.start(audioContext.currentTime);
        oscillator.stop(audioContext.currentTime + 0.15);
      }


      // --- 6. EVENT HANDLERS & INITIALIZATION ---

      /**
       * Central handler for click events on all '.clickable' entities.
       */
      function handleInteraction(event) {
        if (!gameActive && !['btn-replay', 'btn-save-card'].includes(event.currentTarget.id)) return;

        playBeep('neutral');
        const targetId = event.currentTarget.id;

        switch(targetId) {
          case 'btn-direct':
            processPlayerChoice("I'll use a direct approach.", 'ASSERTIVE');
            break;
          case 'btn-distract':
            processPlayerChoice("I'll create a distraction.", 'ASSERTIVE');
            break;
          case 'btn-delegate':
            processPlayerChoice("I'll find someone to delegate to.", 'ASSERTIVE');
            break;
          case 'btn-speak':
            handleSpeakNow();
            break;
          case 'btn-replay':
            startScenario();
            break;
          case 'btn-save-card':
            saveFeedbackCardAsPNG();
            break;
        }
      }

      /**
       * Handles the "Speak Now" button press, coordinating tone and speech analysis.
       */
      async function handleSpeakNow() {
        if (!isMicEnabled) {
          transcriptTextEl.setAttribute('value', 'Mic not enabled. Use the 2D button on screen.');
          playBeep('error');
          return;
        }

        subtitleTextEl.setAttribute('value', 'Speak your response now...');
        const tonePromise = analyzeTone();
        const transcriptPromise = recognition ? startSpeechRecognition() : Promise.resolve("Voice not supported, button fallback.");

        try {
            const [tone, transcript] = await Promise.all([tonePromise, transcriptPromise]);
            processPlayerChoice(transcript, tone);
        } catch (error) {
            console.error(error);
            subtitleTextEl.setAttribute('value', 'Could not process audio. Please use buttons.');
            playBeep('error');
            // If speech fails, fall back to a neutral button press
            setTimeout(() => processPlayerChoice("I hesitated.", "CALM"), 2000);
        }
      }

      /**
       * Draws the feedback card content onto a 2D canvas and triggers a download.
       */
      function saveFeedbackCardAsPNG() {
        const canvas = document.getElementById('feedbackCanvas');
        const ctx = canvas.getContext('2d');

        // Set canvas size
        canvas.width = 600;
        canvas.height = 400;

        // Background
        ctx.fillStyle = '#37474F';
        ctx.fillRect(0, 0, canvas.width, canvas.height);

        // Title
        ctx.fillStyle = '#FFFFFF';
        ctx.font = 'bold 28px sans-serif';
        ctx.textAlign = 'center';
        ctx.fillText('Bystander Coach Feedback', canvas.width / 2, 50);
        
        // Get text from A-Frame entities
        const line1 = document.querySelector('#feedback-line-1').getAttribute('value');
        const line2 = document.querySelector('#feedback-line-2').getAttribute('value');
        const good = document.querySelector('#feedback-good').getAttribute('value');
        const suggestion = document.querySelector('#feedback-suggestion').getAttribute('value');

        // Draw text
        ctx.font = '16px sans-serif';
        ctx.textAlign = 'left';
        ctx.fillStyle = '#CFD8DC';
        ctx.fillText(line1.text || line1, 30, 100);
        ctx.fillText(line2.text || line2, 30, 130);
        
        ctx.fillStyle = '#A5D6A7';
        wrapText(ctx, good.text || good, 30, 180, 540, 20);
        
        ctx.fillStyle = '#FFCC80';
        wrapText(ctx, suggestion.text || suggestion, 30, 260, 540, 20);

        // Trigger download
        const link = document.createElement('a');
        link.download = 'BystanderCoach-Feedback.png';
        link.href = canvas.toDataURL('image/png');
        link.click();
        playBeep('success');
      }

      /**
       * Helper function to wrap text on a 2D canvas.
      */
      function wrapText(context, text, x, y, maxWidth, lineHeight) {
        const words = text.split(' ');
        let line = '';
        for(let n = 0; n < words.length; n++) {
          const testLine = line + words[n] + ' ';
          const metrics = context.measureText(testLine);
          const testWidth = metrics.width;
          if (testWidth > maxWidth && n > 0) {
            context.fillText(line, x, y);
            line = words[n] + ' ';
            y += lineHeight;
          } else {
            line = testLine;
          }
        }
        context.fillText(line, x, y);
      }
      
      // --- SET UP EVENT LISTENERS ---
      // Add click listeners to all clickable entities
      document.querySelectorAll('.clickable').forEach(el => {
        el.addEventListener('click', handleInteraction);

        // Hover feedback listeners
        el.addEventListener('raycaster-intersection', (evt) => {
          hoverDotEl.setAttribute('visible', true);
          const intersectionPoint = evt.detail.intersection.point;
          hoverDotEl.setAttribute('position', intersectionPoint);
        });
        el.addEventListener('raycaster-intersection-cleared', () => {
          hoverDotEl.setAttribute('visible', false);
        });
      });
      
      // 2D UI listener
      document.querySelector('#enableMicButton').addEventListener('click', setupMic);

      // --- START THE APP ---
      startScenario();
    });
  </script>
</body>
</html>